package api

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net"
	"strings"
	"time"

	"github.com/caiatech/govc"
	pb "github.com/caiatech/govc/api/proto"
	"github.com/caiatech/govc/utils"
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/reflection"
	"google.golang.org/grpc/status"
	"google.golang.org/protobuf/types/known/emptypb"
	"google.golang.org/protobuf/types/known/timestamppb"
)

// GRPCServer implements the GoVCService gRPC interface
type GRPCServer struct {
	pb.UnimplementedGoVCServiceServer
	server     *grpc.Server
	repository *govc.Repository
	repoPool   map[string]*govc.Repository
	logger     *log.Logger
	startTime  time.Time
}

// NewGRPCServer creates a new gRPC server instance
func NewGRPCServer(repository *govc.Repository, logger *log.Logger) *GRPCServer {
	return &GRPCServer{
		repository: repository,
		repoPool:   make(map[string]*govc.Repository),
		logger:     logger,
		startTime:  time.Now(),
	}
}

// Start starts the gRPC server on the specified address
func (s *GRPCServer) Start(address string) error {
	lis, err := net.Listen("tcp", address)
	if err != nil {
		return fmt.Errorf("failed to listen: %w", err)
	}

	// Create gRPC server with options for performance
	opts := []grpc.ServerOption{
		grpc.MaxRecvMsgSize(100 * 1024 * 1024), // 100MB max message size
		grpc.MaxSendMsgSize(100 * 1024 * 1024), // 100MB max message size
		grpc.MaxConcurrentStreams(1000),        // Support 1000 concurrent streams
	}

	s.server = grpc.NewServer(opts...)
	pb.RegisterGoVCServiceServer(s.server, s)

	// Enable reflection for debugging
	reflection.Register(s.server)

	s.logger.Printf("gRPC server starting on %s", address)
	return s.server.Serve(lis)
}

// Stop gracefully stops the gRPC server
func (s *GRPCServer) Stop() {
	if s.server != nil {
		s.server.GracefulStop()
	}
}

// getRepository gets a repository by ID, defaults to main repository if empty
func (s *GRPCServer) getRepository(repositoryID string) (*govc.Repository, error) {
	if repositoryID == "" {
		return s.repository, nil
	}

	if repo, exists := s.repoPool[repositoryID]; exists {
		return repo, nil
	}

	return nil, status.Errorf(codes.NotFound, "repository not found: %s", repositoryID)
}

// Repository Management

func (s *GRPCServer) CreateRepository(ctx context.Context, req *pb.CreateRepositoryRequest) (*pb.CreateRepositoryResponse, error) {
	// For now, create in-memory repository
	repo := govc.NewRepository()
	s.repoPool[req.Id] = repo

	return &pb.CreateRepositoryResponse{
		Id:        req.Id,
		Name:      req.Name,
		CreatedAt: timestamppb.Now(),
	}, nil
}

func (s *GRPCServer) GetRepository(ctx context.Context, req *pb.GetRepositoryRequest) (*pb.GetRepositoryResponse, error) {
	_, err := s.getRepository(req.Id)
	if err != nil {
		return nil, err
	}

	return &pb.GetRepositoryResponse{
		Id:          req.Id,
		Name:        req.Id,
		Description: fmt.Sprintf("Repository %s", req.Id),
		CreatedAt:   timestamppb.Now(),
		Metadata:    make(map[string]string),
	}, nil
}

func (s *GRPCServer) DeleteRepository(ctx context.Context, req *pb.DeleteRepositoryRequest) (*emptypb.Empty, error) {
	if req.Id == "" {
		return nil, status.Errorf(codes.InvalidArgument, "cannot delete main repository")
	}

	delete(s.repoPool, req.Id)
	return &emptypb.Empty{}, nil
}

func (s *GRPCServer) ListRepositories(ctx context.Context, req *pb.ListRepositoriesRequest) (*pb.ListRepositoriesResponse, error) {
	var repos []*pb.GetRepositoryResponse

	// Add main repository
	repos = append(repos, &pb.GetRepositoryResponse{
		Id:          "",
		Name:        "main",
		Description: "Main repository",
		CreatedAt:   timestamppb.New(s.startTime),
	})

	// Add pooled repositories
	for id := range s.repoPool {
		repos = append(repos, &pb.GetRepositoryResponse{
			Id:          id,
			Name:        id,
			Description: fmt.Sprintf("Repository %s", id),
			CreatedAt:   timestamppb.Now(),
		})
	}

	// Apply pagination
	start := int(req.Offset)
	end := start + int(req.Limit)
	if req.Limit == 0 {
		end = len(repos)
	}
	if start > len(repos) {
		start = len(repos)
	}
	if end > len(repos) {
		end = len(repos)
	}

	return &pb.ListRepositoriesResponse{
		Repositories: repos[start:end],
		Total:        int32(len(repos)),
	}, nil
}

// Blob Operations

func (s *GRPCServer) StoreBlob(ctx context.Context, req *pb.StoreBlobRequest) (*pb.StoreBlobResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	hash, err := repo.StoreBlob(req.Content)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to store blob: %v", err)
	}

	return &pb.StoreBlobResponse{
		Hash: hash,
		Size: int64(len(req.Content)),
	}, nil
}

func (s *GRPCServer) GetBlob(ctx context.Context, req *pb.GetBlobRequest) (*pb.GetBlobResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	blob, err := repo.GetBlob(req.Hash)
	if err != nil {
		return nil, status.Errorf(codes.NotFound, "blob not found: %v", err)
	}

	return &pb.GetBlobResponse{
		Content: blob.Content,
		Hash:    blob.Hash,
		Size:    blob.Size,
	}, nil
}

func (s *GRPCServer) StoreBlobWithDelta(ctx context.Context, req *pb.StoreBlobWithDeltaRequest) (*pb.StoreBlobWithDeltaResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	hash, err := repo.StoreBlobWithDelta(req.Content)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to store blob with delta: %v", err)
	}

	// Get compression info if available
	blob, _ := repo.GetBlobWithDelta(hash)
	compressedSize := int64(len(req.Content))
	compressionRatio := float32(1.0)
	
	if blob != nil && len(blob.Content) > 0 {
		compressionRatio = float32(compressedSize) / float32(len(blob.Content))
	}

	return &pb.StoreBlobWithDeltaResponse{
		Hash:             hash,
		Size:             int64(len(req.Content)),
		CompressedSize:   compressedSize,
		CompressionRatio: compressionRatio,
	}, nil
}

func (s *GRPCServer) GetBlobWithDelta(ctx context.Context, req *pb.GetBlobWithDeltaRequest) (*pb.GetBlobWithDeltaResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	blob, err := repo.GetBlobWithDelta(req.Hash)
	if err != nil {
		return nil, status.Errorf(codes.NotFound, "blob not found: %v", err)
	}

	return &pb.GetBlobWithDeltaResponse{
		Content:        blob.Content,
		Hash:           blob.Hash,
		Size:           blob.Size,
		CompressedSize: blob.Size, // Simplified for now
		WasCompressed:  false,     // Simplified for now
	}, nil
}

// File Operations

func (s *GRPCServer) AddFile(ctx context.Context, req *pb.AddFileRequest) (*pb.AddFileResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	err = repo.AtomicCreateFile(req.Path, req.Content, fmt.Sprintf("Add file %s", req.Path))
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to add file: %v", err)
	}

	// Calculate hash for response
	hash, _ := repo.StoreBlobWithDelta(req.Content)

	return &pb.AddFileResponse{
		Hash: hash,
		Size: int64(len(req.Content)),
	}, nil
}

func (s *GRPCServer) ReadFile(ctx context.Context, req *pb.ReadFileRequest) (*pb.ReadFileResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	content, err := repo.ReadFile(req.Path)
	if err != nil {
		return nil, status.Errorf(codes.NotFound, "file not found: %v", err)
	}

	// Calculate hash
	hash, _ := repo.StoreBlobWithDelta(content)

	return &pb.ReadFileResponse{
		Content:      content,
		Hash:         hash,
		Size:         int64(len(content)),
		LastModified: timestamppb.Now(), // Simplified
	}, nil
}

func (s *GRPCServer) WriteFile(ctx context.Context, req *pb.WriteFileRequest) (*pb.WriteFileResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	err = repo.AtomicCreateFile(req.Path, req.Content, fmt.Sprintf("Write file %s", req.Path))
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to write file: %v", err)
	}

	hash, _ := repo.StoreBlobWithDelta(req.Content)

	return &pb.WriteFileResponse{
		Hash: hash,
		Size: int64(len(req.Content)),
	}, nil
}

func (s *GRPCServer) RemoveFile(ctx context.Context, req *pb.RemoveFileRequest) (*emptypb.Empty, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	err = repo.RemoveFile(req.Path)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to remove file: %v", err)
	}

	return &emptypb.Empty{}, nil
}

func (s *GRPCServer) MoveFile(ctx context.Context, req *pb.MoveFileRequest) (*emptypb.Empty, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	// Read file, create at new location, remove old
	content, err := repo.ReadFile(req.FromPath)
	if err != nil {
		return nil, status.Errorf(codes.NotFound, "source file not found: %v", err)
	}

	err = repo.AtomicCreateFile(req.ToPath, content, fmt.Sprintf("Move %s to %s", req.FromPath, req.ToPath))
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to create file at new location: %v", err)
	}

	err = repo.RemoveFile(req.FromPath)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to remove source file: %v", err)
	}

	return &emptypb.Empty{}, nil
}

// Commit Operations

func (s *GRPCServer) Commit(ctx context.Context, req *pb.CommitRequest) (*pb.CommitResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	commit, err := repo.CreateCommit(req.Message, req.Author)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to create commit: %v", err)
	}

	return &pb.CommitResponse{
		Hash:      commit.Hash,
		Message:   commit.Message,
		Author:    commit.Author,
		Timestamp: timestamppb.New(commit.Timestamp),
	}, nil
}

func (s *GRPCServer) GetCommit(ctx context.Context, req *pb.GetCommitRequest) (*pb.GetCommitResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	commit, err := repo.GetCommit(req.Hash)
	if err != nil {
		return nil, status.Errorf(codes.NotFound, "commit not found: %v", err)
	}

	// Convert file changes
	var changes []*pb.FileChange
	for path, change := range commit.Changes {
		changes = append(changes, &pb.FileChange{
			Path: path,
			Type: change.Type,
			Hash: change.Hash,
		})
	}

	return &pb.GetCommitResponse{
		Hash:         commit.Hash,
		Message:      commit.Message,
		Author:       commit.Author,
		Timestamp:    timestamppb.New(commit.Timestamp),
		ParentHashes: commit.Parents,
		Changes:      changes,
	}, nil
}

func (s *GRPCServer) ListCommits(ctx context.Context, req *pb.ListCommitsRequest) (*pb.ListCommitsResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	// Build query request
	queryReq := &govc.QueryRequest{
		Type:   govc.QueryByCommit,
		Limit:  int(req.Limit),
		Offset: int(req.Offset),
	}

	if req.Author != "" {
		queryReq.Type = govc.QueryByAuthor
		queryReq.Query = req.Author
	}

	result, err := repo.Query(queryReq)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to query commits: %v", err)
	}

	var commits []*pb.GetCommitResponse
	for _, commit := range result.Commits {
		var changes []*pb.FileChange
		for path, change := range commit.Changes {
			changes = append(changes, &pb.FileChange{
				Path: path,
				Type: change.Type,
				Hash: change.Hash,
			})
		}

		commits = append(commits, &pb.GetCommitResponse{
			Hash:         commit.Hash,
			Message:      commit.Message,
			Author:       commit.Author,
			Timestamp:    timestamppb.New(commit.Timestamp),
			ParentHashes: commit.Parents,
			Changes:      changes,
		})
	}

	return &pb.ListCommitsResponse{
		Commits: commits,
		Total:   int32(len(commits)),
	}, nil
}

// Search Operations

func (s *GRPCServer) FullTextSearch(ctx context.Context, req *pb.FullTextSearchRequest) (*pb.FullTextSearchResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	// Initialize advanced search if needed
	if err := repo.InitializeAdvancedSearch(); err != nil {
		return nil, status.Errorf(codes.Internal, "failed to initialize search: %v", err)
	}

	searchReq := &govc.FullTextSearchRequest{
		Query:           req.Query,
		FileTypes:       req.FileTypes,
		MaxSize:         req.MaxSize,
		MinScore:        req.MinScore,
		IncludeContent:  req.IncludeContent,
		HighlightLength: int(req.HighlightLength),
		Limit:           int(req.Limit),
		Offset:          int(req.Offset),
		SortBy:          req.SortBy,
	}

	start := time.Now()
	response, err := repo.FullTextSearch(searchReq)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "search failed: %v", err)
	}

	// Convert results
	var results []*pb.SearchResult
	for _, result := range response.Results {
		doc := &pb.SearchDocument{
			Path:         result.Document.Path,
			Hash:         result.Document.Hash,
			Size:         result.Document.Size,
			LastModified: timestamppb.New(result.Document.LastModified),
			Content:      result.Document.Content,
			ContentType:  result.Document.ContentType,
		}

		results = append(results, &pb.SearchResult{
			Document:   doc,
			Score:      result.Score,
			Highlights: result.Highlights,
		})
	}

	return &pb.FullTextSearchResponse{
		Results:     results,
		Total:       int32(response.Total),
		QueryTimeMs: float64(time.Since(start).Nanoseconds()) / 1e6,
	}, nil
}

func (s *GRPCServer) ExecuteSQLQuery(ctx context.Context, req *pb.ExecuteSQLQueryRequest) (*pb.ExecuteSQLQueryResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	start := time.Now()
	result, err := repo.ExecuteSQLQuery(req.SqlQuery)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "SQL query failed: %v", err)
	}

	// Convert rows
	var rows []*pb.QueryRow
	for _, row := range result.Rows {
		fields := make(map[string]string)
		for key, value := range row {
			fields[key] = fmt.Sprintf("%v", value)
		}
		rows = append(rows, &pb.QueryRow{Fields: fields})
	}

	return &pb.ExecuteSQLQueryResponse{
		Rows:        rows,
		Total:       int32(result.Total),
		QueryTimeMs: float64(time.Since(start).Nanoseconds()) / 1e6,
		ExecutedSql: result.ExecutedSQL,
	}, nil
}

func (s *GRPCServer) SearchWithAggregation(ctx context.Context, req *pb.SearchWithAggregationRequest) (*pb.SearchWithAggregationResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	// Convert request
	searchReq := &govc.FullTextSearchRequest{
		Query:           req.Query.Query,
		FileTypes:       req.Query.FileTypes,
		MaxSize:         req.Query.MaxSize,
		MinScore:        req.Query.MinScore,
		IncludeContent:  req.Query.IncludeContent,
		HighlightLength: int(req.Query.HighlightLength),
		Limit:           int(req.Query.Limit),
		Offset:          int(req.Query.Offset),
		SortBy:          req.Query.SortBy,
	}

	aggReq := &govc.AggregationRequest{
		Query:        searchReq,
		GroupBy:      req.GroupBy,
		Aggregations: req.Aggregations,
		TimeRange:    req.TimeRange,
	}

	response, err := repo.SearchWithAggregation(aggReq)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "aggregation failed: %v", err)
	}

	// Convert groups
	var groups []*pb.AggregationGroup
	for _, group := range response.Groups {
		var sampleResults []*pb.SearchResult
		for _, result := range group.SampleResults {
			doc := &pb.SearchDocument{
				Path:         result.Document.Path,
				Hash:         result.Document.Hash,
				Size:         result.Document.Size,
				LastModified: timestamppb.New(result.Document.LastModified),
				Content:      result.Document.Content,
				ContentType:  result.Document.ContentType,
			}

			sampleResults = append(sampleResults, &pb.SearchResult{
				Document:   doc,
				Score:      result.Score,
				Highlights: result.Highlights,
			})
		}

		groups = append(groups, &pb.AggregationGroup{
			GroupValue:    group.GroupValue,
			Count:         int32(group.Count),
			Metrics:       group.Metrics,
			SampleResults: sampleResults,
		})
	}

	summary := &pb.AggregationSummary{
		TotalDocuments: int32(response.Summary.TotalDocuments),
		TotalGroups:    int32(response.Summary.TotalGroups),
		Metrics:        response.Summary.Metrics,
	}

	return &pb.SearchWithAggregationResponse{
		Groups:  groups,
		Summary: summary,
	}, nil
}

// Streaming Operations

func (s *GRPCServer) StreamBlob(stream pb.GoVCService_StreamBlobServer) error {
	// Get the first request to understand what to stream
	req, err := stream.Recv()
	if err != nil {
		return status.Errorf(codes.InvalidArgument, "failed to receive request: %v", err)
	}

	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return err
	}

	// Get the blob
	blob, err := repo.GetBlobWithDelta(req.Hash)
	if err != nil {
		return status.Errorf(codes.NotFound, "blob not found: %v", err)
	}

	// Send metadata first
	chunkSize := int(req.ChunkSize)
	if chunkSize <= 0 {
		chunkSize = 64 * 1024 // 64KB default
	}

	totalSize := int64(len(blob.Content))
	chunkCount := int((totalSize + int64(chunkSize) - 1) / int64(chunkSize))
	streamID := fmt.Sprintf("grpc_stream_%d", time.Now().Unix())

	metadata := &pb.StreamMetadata{
		StreamId:    streamID,
		TotalSize:   totalSize,
		ChunkCount:  int32(chunkCount),
		ContentType: "application/octet-stream",
		Checksum:    utils.CalculateHashString(blob.Content),
	}

	err = stream.Send(&pb.StreamBlobResponse{
		Response: &pb.StreamBlobResponse_Metadata{Metadata: metadata},
	})
	if err != nil {
		return err
	}

	// Stream chunks
	for i := 0; i < chunkCount; i++ {
		start := i * chunkSize
		end := start + chunkSize
		if end > len(blob.Content) {
			end = len(blob.Content)
		}

		chunkData := blob.Content[start:end]
		chunk := &pb.StreamChunk{
			StreamId:    streamID,
			SequenceNum: int32(i),
			Data:        chunkData,
			Checksum:    utils.CalculateHashString(chunkData),
			IsLast:      i == chunkCount-1,
		}

		err = stream.Send(&pb.StreamBlobResponse{
			Response: &pb.StreamBlobResponse_Chunk{Chunk: chunk},
		})
		if err != nil {
			return err
		}

		// Send progress every 10 chunks
		if i%10 == 0 || chunk.IsLast {
			progress := &pb.StreamProgress{
				StreamId:       streamID,
				BytesStreamed:  int64(end),
				TotalBytes:     totalSize,
				ChunksStreamed: int32(i + 1),
				TotalChunks:    int32(chunkCount),
				TransferRateMbps: 0, // Calculate if needed
				Status:         "streaming",
			}
			
			if chunk.IsLast {
				progress.Status = "completed"
			}

			err = stream.Send(&pb.StreamBlobResponse{
				Response: &pb.StreamBlobResponse_Progress{Progress: progress},
			})
			if err != nil {
				return err
			}
		}
	}

	return nil
}

func (s *GRPCServer) UploadBlobStream(stream pb.GoVCService_UploadBlobStreamServer) error {
	var buffer []byte
	var metadata *pb.UploadMetadata
	chunksReceived := 0

	for {
		req, err := stream.Recv()
		if err == io.EOF {
			// End of stream, store the blob
			break
		}
		if err != nil {
			return status.Errorf(codes.Internal, "failed to receive chunk: %v", err)
		}

		switch r := req.Request.(type) {
		case *pb.UploadBlobStreamRequest_Metadata:
			metadata = r.Metadata
		case *pb.UploadBlobStreamRequest_Chunk:
			buffer = append(buffer, r.Chunk.Data...)
			chunksReceived++
		}
	}

	if metadata == nil {
		return status.Errorf(codes.InvalidArgument, "no metadata received")
	}

	// Store the assembled blob
	repo, err := s.getRepository("") // Use default repo for now
	if err != nil {
		return err
	}

	hash, err := repo.StoreBlobWithDelta(buffer)
	if err != nil {
		return status.Errorf(codes.Internal, "failed to store blob: %v", err)
	}

	return stream.SendAndClose(&pb.UploadBlobStreamResponse{
		Hash:            hash,
		Size:            int64(len(buffer)),
		ChunksReceived:  int32(chunksReceived),
		Checksum:        utils.CalculateHashString(buffer),
	})
}

// Health and Status

func (s *GRPCServer) GetHealth(ctx context.Context, _ *emptypb.Empty) (*pb.HealthResponse, error) {
	checks := map[string]string{
		"grpc_server": "healthy",
		"repository":  "healthy",
	}

	if s.repository == nil {
		checks["repository"] = "unhealthy"
	}

	status := "healthy"
	for _, check := range checks {
		if check != "healthy" {
			status = "unhealthy"
			break
		}
	}

	return &pb.HealthResponse{
		Status:        status,
		Checks:        checks,
		Timestamp:     timestamppb.Now(),
		UptimeSeconds: time.Since(s.startTime).Seconds(),
	}, nil
}

func (s *GRPCServer) GetStatus(ctx context.Context, req *pb.GetStatusRequest) (*pb.GetStatusResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	// Get repository status
	status, err := repo.GetStatus()
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to get status: %v", err)
	}

	var statusEntries []string
	for _, entry := range status.Files {
		statusEntries = append(statusEntries, fmt.Sprintf("%s: %s", entry.Path, entry.Status))
	}

	return &pb.GetStatusResponse{
		RepositoryId:  req.RepositoryId,
		CurrentBranch: status.Branch,
		StagedFiles:   int32(len(status.StagedFiles)),
		UnstagedFiles: int32(len(status.UnstagedFiles)),
		UntrackedFiles: int32(len(status.UntrackedFiles)),
		StatusEntries: statusEntries,
	}, nil
}

// Batch Operations

func (s *GRPCServer) BatchOperations(ctx context.Context, req *pb.BatchOperationsRequest) (*pb.BatchOperationsResponse, error) {
	repo, err := s.getRepository(req.RepositoryId)
	if err != nil {
		return nil, err
	}

	start := time.Now()
	results := make([]*pb.BatchOperationResult, len(req.Operations))
	allSuccess := true

	for i, op := range req.Operations {
		result, err := s.executeBatchOperation(repo, op)
		results[i] = result
		if err != nil || !result.Success {
			allSuccess = false
		}
	}

	executionTime := time.Since(start).Seconds() * 1000 // Convert to milliseconds

	return &pb.BatchOperationsResponse{
		Results:         results,
		Success:         allSuccess,
		ExecutionTimeMs: executionTime,
	}, nil
}

func (s *GRPCServer) executeBatchOperation(repo *govc.Repository, op *pb.BatchOperation) (*pb.BatchOperationResult, error) {
	switch strings.ToLower(op.Type) {
	case "store_blob":
		// Parse JSON params for store blob operation
		var params struct {
			Content string `json:"content"`
		}
		if err := json.Unmarshal(op.Params, &params); err != nil {
			return &pb.BatchOperationResult{
				Id:      op.Id,
				Success: false,
				Error:   fmt.Sprintf("invalid params: %v", err),
			}, nil
		}

		hash, err := repo.StoreBlobWithDelta([]byte(params.Content))
		if err != nil {
			return &pb.BatchOperationResult{
				Id:      op.Id,
				Success: false,
				Error:   err.Error(),
			}, nil
		}

		resultData, _ := json.Marshal(map[string]interface{}{
			"hash": hash,
			"size": len(params.Content),
		})

		return &pb.BatchOperationResult{
			Id:      op.Id,
			Success: true,
			Result:  resultData,
		}, nil

	default:
		return &pb.BatchOperationResult{
			Id:      op.Id,
			Success: false,
			Error:   fmt.Sprintf("unsupported operation type: %s", op.Type),
		}, nil
	}
}